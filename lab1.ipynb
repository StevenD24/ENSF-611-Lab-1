{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEte-npThkXN"
      },
      "source": [
        "# Lab1 - Scikit-learn\n",
        "Author: *Steven Duong (30022492)*\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "The goal of this lab is to become familiar with the scikit-learn library.\n",
        "\n",
        "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t3AIihxRhkXR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ONaKpnChkXS"
      },
      "source": [
        "## 2. Classification\n",
        "\n",
        "Using yellowbrick spam - classification  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "The goal is to investigate `LogisticRegression(max_iter=2000)` and effects of reducing the number of features and number of samples on classification performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfzTh4MUhkXS"
      },
      "source": [
        "### 2.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EC4DX0SlhkXT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_classifier_accuracy(model, X, y):\n",
        "    '''Calculate train and validation accuracy of classifier (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn classifier): Classifier to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training accuracy, validation accuracy\n",
        "    '''\n",
        "    \n",
        "    # Creating train, test and split for the NumPy arrays\n",
        "    # X is the feature matrix, while y is the target vector\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=956)\n",
        "    \n",
        "    # Building the model on the training set \n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicting the outcome with the training set\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    # Computing the accuracy of the prediction\n",
        "    acc_train = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    # Predict the outcome with the validation set\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    \n",
        "    # Computing the accuracy of the prediction\n",
        "    acc_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    return (acc_train, acc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7BwD1BghkXT"
      },
      "source": [
        "### 2.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_spam()`, load the spam data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print size and type of `X` and `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWizoFIRhkXT",
        "outputId": "f7c65ff6-85d0-46d4-cbc4-331759607e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: 262200\n",
            "Type of X: \n",
            "word_freq_make                float64\n",
            "word_freq_address             float64\n",
            "word_freq_all                 float64\n",
            "word_freq_3d                  float64\n",
            "word_freq_our                 float64\n",
            "word_freq_over                float64\n",
            "word_freq_remove              float64\n",
            "word_freq_internet            float64\n",
            "word_freq_order               float64\n",
            "word_freq_mail                float64\n",
            "word_freq_receive             float64\n",
            "word_freq_will                float64\n",
            "word_freq_people              float64\n",
            "word_freq_report              float64\n",
            "word_freq_addresses           float64\n",
            "word_freq_free                float64\n",
            "word_freq_business            float64\n",
            "word_freq_email               float64\n",
            "word_freq_you                 float64\n",
            "word_freq_credit              float64\n",
            "word_freq_your                float64\n",
            "word_freq_font                float64\n",
            "word_freq_000                 float64\n",
            "word_freq_money               float64\n",
            "word_freq_hp                  float64\n",
            "word_freq_hpl                 float64\n",
            "word_freq_george              float64\n",
            "word_freq_650                 float64\n",
            "word_freq_lab                 float64\n",
            "word_freq_labs                float64\n",
            "word_freq_telnet              float64\n",
            "word_freq_857                 float64\n",
            "word_freq_data                float64\n",
            "word_freq_415                 float64\n",
            "word_freq_85                  float64\n",
            "word_freq_technology          float64\n",
            "word_freq_1999                float64\n",
            "word_freq_parts               float64\n",
            "word_freq_pm                  float64\n",
            "word_freq_direct              float64\n",
            "word_freq_cs                  float64\n",
            "word_freq_meeting             float64\n",
            "word_freq_original            float64\n",
            "word_freq_project             float64\n",
            "word_freq_re                  float64\n",
            "word_freq_edu                 float64\n",
            "word_freq_table               float64\n",
            "word_freq_conference          float64\n",
            "char_freq_;                   float64\n",
            "char_freq_(                   float64\n",
            "char_freq_[                   float64\n",
            "char_freq_!                   float64\n",
            "char_freq_$                   float64\n",
            "char_freq_#                   float64\n",
            "capital_run_length_average    float64\n",
            "capital_run_length_longest      int64\n",
            "capital_run_length_total        int64\n",
            "dtype: object\n",
            "Size of y: 4600\n",
            "Type of y: int64\n"
          ]
        }
      ],
      "source": [
        "from yellowbrick.datasets.loaders import load_spam\n",
        "\n",
        "# loading in spam data set into feature matrix X and target vector y\n",
        "X, y = load_spam()\n",
        "\n",
        "# Printing size and type of X and y\n",
        "print(f\"Size of X: {X.size}\\nType of X: \\n{X.dtypes}\\nSize of y: {y.size}\\nType of y: {y.dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS-6tGsthkXU"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVQPFCuUhkXU",
        "outputId": "e08d31cc-4c6e-4308-b401-cbc2be41e0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X_small: 2622\n",
            "Type of X_small: word_freq_make                float64\n",
            "word_freq_address             float64\n",
            "word_freq_all                 float64\n",
            "word_freq_3d                  float64\n",
            "word_freq_our                 float64\n",
            "word_freq_over                float64\n",
            "word_freq_remove              float64\n",
            "word_freq_internet            float64\n",
            "word_freq_order               float64\n",
            "word_freq_mail                float64\n",
            "word_freq_receive             float64\n",
            "word_freq_will                float64\n",
            "word_freq_people              float64\n",
            "word_freq_report              float64\n",
            "word_freq_addresses           float64\n",
            "word_freq_free                float64\n",
            "word_freq_business            float64\n",
            "word_freq_email               float64\n",
            "word_freq_you                 float64\n",
            "word_freq_credit              float64\n",
            "word_freq_your                float64\n",
            "word_freq_font                float64\n",
            "word_freq_000                 float64\n",
            "word_freq_money               float64\n",
            "word_freq_hp                  float64\n",
            "word_freq_hpl                 float64\n",
            "word_freq_george              float64\n",
            "word_freq_650                 float64\n",
            "word_freq_lab                 float64\n",
            "word_freq_labs                float64\n",
            "word_freq_telnet              float64\n",
            "word_freq_857                 float64\n",
            "word_freq_data                float64\n",
            "word_freq_415                 float64\n",
            "word_freq_85                  float64\n",
            "word_freq_technology          float64\n",
            "word_freq_1999                float64\n",
            "word_freq_parts               float64\n",
            "word_freq_pm                  float64\n",
            "word_freq_direct              float64\n",
            "word_freq_cs                  float64\n",
            "word_freq_meeting             float64\n",
            "word_freq_original            float64\n",
            "word_freq_project             float64\n",
            "word_freq_re                  float64\n",
            "word_freq_edu                 float64\n",
            "word_freq_table               float64\n",
            "word_freq_conference          float64\n",
            "char_freq_;                   float64\n",
            "char_freq_(                   float64\n",
            "char_freq_[                   float64\n",
            "char_freq_!                   float64\n",
            "char_freq_$                   float64\n",
            "char_freq_#                   float64\n",
            "capital_run_length_average    float64\n",
            "capital_run_length_longest      int64\n",
            "capital_run_length_total        int64\n",
            "dtype: object\n",
            "Size of y_small: 46\n",
            "Type of y_small: int64\n"
          ]
        }
      ],
      "source": [
        "# Creating a feature matrix that contain only 1% of the rows\n",
        "X_small, y_test, y_small, y_text = train_test_split(X, y, random_state=174, train_size = 0.01)\n",
        "\n",
        "# Printing the size and type of X_small and y_small\n",
        "print(f\"Size of X_small: {X_small.size}\\nType of X_small: {X_small.dtypes}\\nSize of y_small: {y_small.size}\\nType of y_small: {y_small.dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1n_zAArhkXU"
      },
      "source": [
        "### 2.3 Train and evaluate models\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "4. Call your convenience function `get_classifier_accuracy()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygghypEyhkXV",
        "outputId": "3d6a08cb-c042-4dc7-990f-465c54c86ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for X and y:\n",
            "Training accuracy = 0.93449\n",
            "Validation accuracy = 0.91826\n",
            "\n",
            "Results for first two columns of X:\n",
            "Training accuracy = 0.60899\n",
            "Validation accuracy = 0.61304\n",
            "\n",
            "Results for X_small and y_small:\n",
            "Training accuracy = 0.94118\n",
            "Validation accuracy = 0.75000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiating model Logistic Regression\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "# Creating a Pandas DataFrame\n",
        "results = pd.DataFrame(columns=['Data size', 'training accuracy', 'validation accuracy'])\n",
        "    \n",
        "# Calculate the accuracy using X and y\n",
        "train_acc, val_acc = get_classifier_accuracy(model, X, y)\n",
        "print(\"Results for X and y:\")\n",
        "print(\"Training accuracy = {0:.5f}\".format(train_acc))\n",
        "print(\"Validation accuracy = {0:.5f}\".format(val_acc))\n",
        "\n",
        "# Calculate the accuracy using X and y\n",
        "train_acc, val_acc = get_classifier_accuracy(model, X.iloc[:,:2], y)\n",
        "print(\"\\nResults for first two columns of X:\")\n",
        "print(\"Training accuracy = {0:.5f}\".format(train_acc))\n",
        "print(\"Validation accuracy = {0:.5f}\".format(val_acc))\n",
        "\n",
        "\n",
        "# Calculate the accuracy using X_small and y_small\n",
        "train_acc, val_acc = get_classifier_accuracy(model, X_small, y_small)\n",
        "print(\"\\nResults for X_small and y_small:\")\n",
        "print(\"Training accuracy = {0:.5f}\".format(train_acc))\n",
        "print(\"Validation accuracy = {0:.5f}\".format(val_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM-am1NWhkXV"
      },
      "source": [
        "### 2.4 Questions\n",
        "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
        "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy5tHd6KhkXV"
      },
      "source": [
        "## 3. Regression\n",
        "\n",
        "Using yellowbrick energy - regression  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
        "\n",
        "The goal is to investigate `LinearRegression()` and effects of reducing the number of features and number of samples on regression performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b225bkgOhkXV"
      },
      "source": [
        "### 3.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFkC1DDihkXW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_regressor_mse(model, X, y):\n",
        "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn regressor): Regressor to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training mse, validation mse\n",
        "    \n",
        "    '''\n",
        "   \n",
        "    #TODO: IMPLEMENT FUNCTION BODY\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_rnIH3khkXW"
      },
      "source": [
        "### 3.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_energy()` load the energy data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print dimensions and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65YqsSa_hkXW"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOZVndxahkXW"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q_mJlN3hkXW"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pln8lwBvhkXW"
      },
      "source": [
        "### 3.3 Train and evaluate models\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
        "4. Call your convenience function `get_regressor_mse()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caedsKrLhkXX"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfdhk9B5hkXX"
      },
      "source": [
        "### 3.4 Questions\n",
        "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
        "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExfUaXh9hkXX"
      },
      "source": [
        "## 4. Observations/Interpretation\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn60V5N5hkXX"
      },
      "source": [
        "## 5. Reflection\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}